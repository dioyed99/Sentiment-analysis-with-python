{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from confluent_kafka import Producer, Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka configuration\n",
    "bootstrap_servers = \"localhost:9092\"\n",
    "kafka_topic = \"reddit\"\n",
    "producer = Producer({'bootstrap.servers': bootstrap_servers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1684524895.380|MAXPOLL|rdkafka#consumer-5| [thrd:main]: Application maximum poll interval (300000ms) exceeded by 186ms (adjust max.poll.interval.ms for long-running message processing): leaving group\n"
     ]
    }
   ],
   "source": [
    "# Configuration du consommateur\n",
    "config = {'bootstrap.servers': bootstrap_servers, 'group.id': 'Xmen', 'auto.offset.reset': 'earliest'}\n",
    "\n",
    "# Création du consommateur\n",
    "consumer = Consumer(config)\n",
    "\n",
    "# S'abonner à un ou plusieurs topics\n",
    "topics = ['reddit']\n",
    "consumer.subscribe(topics)\n",
    "\n",
    "tweets_consumer = []\n",
    "# Consommer les messages\n",
    "while True:\n",
    "    \n",
    "    message = consumer.poll(1.0)  # Attendre pendant 1 seconde au maximum\n",
    "    \n",
    "    if message is None:\n",
    "        continue\n",
    "    \n",
    "    if message.error():\n",
    "        print(\"Erreur lors de la consommation : {}\".format(message.error()))\n",
    "        continue\n",
    "    \n",
    "    # Traitement du message\n",
    "    # tweets_consumer.append(eval(message.value().decode('latin1', 'surrogateescape')))\n",
    "    print(\"Message reçu : {}\".format(message.value().decode('latin1')))\n",
    "    \n",
    "    df_new_tweets = pd.DataFrame([eval(message.value().decode('latin1'))])\n",
    "    try:\n",
    "        df_tweets = pd.read_csv(\"df_tweets.csv\")\n",
    "    except:\n",
    "        try:\n",
    "            df_new_tweets.to_csv(\"df_tweets.csv\", index=False)\n",
    "            continue\n",
    "        except:\n",
    "            continue\n",
    "    if not df_new_tweets.equals(df_tweets):\n",
    "        try:\n",
    "            concat_data = pd.concat([df_tweets, df_new_tweets])\n",
    "            concat_data = concat_data.drop_duplicates(keep=\"last\")\n",
    "            concat_data.to_csv(\"df_tweets.csv\", index=False)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "# Fermeture du consommateur\n",
    "consumer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
